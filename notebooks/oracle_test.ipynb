{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_path = \"/data/SSD/flickr30k/annotations/test.json\"\n",
    "image_path = \"/data/SSD/flickr30k/images\"\n",
    "annotations = json.load(open(ann_path))\n",
    "all_image = [annotations[i][\"image\"] for i in range(len(annotations))]\n",
    "all_caption = [annotations[i][\"caption\"] for i in range(len(annotations))]\n",
    "all_caption = [item for sublist in all_caption for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = 2\n",
    "\n",
    "top_k_image_path = f\"/project/Deep-Clustering/other/retrieval_res/top_k_image_indices_{indices}.pt\"\n",
    "top_k_text_path = f\"/project/Deep-Clustering/other/retrieval_res/top_k_text_indices_{indices}.pt\"\n",
    "\n",
    "top_k_image_indices = torch.load(top_k_image_path)\n",
    "top_k_text_indices = torch.load(top_k_text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "index = 1\n",
    "image = all_image[index]\n",
    "image = Image.open(os.path.join(image_path, image)).convert(\"RGB\")\n",
    "plt.imshow(image)\n",
    "caption = annotations[index][\"caption\"]\n",
    "print(*caption, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image-text retrieval\n",
    "\n",
    "text_ids = top_k_text_indices[index]\n",
    "\n",
    "caption_retrived = [all_caption[i] for i in text_ids]\n",
    "print(\"#####Retrieved top k text#####\")\n",
    "print(*caption_retrived, sep=\"\\n\")\n",
    "\n",
    "# compair captions which are not in caption\n",
    "caption_new = [\n",
    "    caption[i] for cr in caption_retrived for i, cr in enumerate(caption) if cr not in caption\n",
    "]\n",
    "print(\"#####New caption#####\")\n",
    "print(*caption_new, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = top_k_image_indices[index]\n",
    "\n",
    "image_retrieved = [all_image[i] for i in image_ids]\n",
    "print(\"#####Retrieved top k image#####\")\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, image in enumerate(image_retrieved):\n",
    "    image = Image.open(os.path.join(image_path, image)).convert(\"RGB\")\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepclustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
